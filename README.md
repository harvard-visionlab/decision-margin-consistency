[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/?usp=sharing)

# Analysis code from "Quantifying agreement between humans and machines (or any model) using performance-concordance to overcome internal noise in humans"

Performance-concordance is an analysis method for measuring agreement between two decision making systems (e.g., humans vs. deep neural network models), assessing whether those systems have a tendency to make errors on the same inputs, while aggregating across stimulus repetitions or observers to cancel out internal noise and isolate stimulus-level agreement. Like error-consistency ([Geirhos et al.]([arXiv](https://arxiv.org/abs/2006.16736)), this method enables a fine-grained analysis, assessing agreement at the level of individual sitmuli. The advantage of performance-concordance is that it can overcome stimulus-independent noise that can dominate human responses and mask high-levels of stimulus-level agreement. Re-analysis of existing datasets show that human-human agreement is greater than previously estimated, widening the gap between deep neural network models and human observers. The paper is available on [arXiv]().


